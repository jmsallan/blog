---
title: A workflow for Binary Classification with Tidymodels
author: Jose M Sallan
date: '2021-04-22'
slug: a-workflow-for-binary-classification-with-tidymodels
categories:
  - R
tags:
  - machine learning
  - tidymodels
meta_img: images/image.png
description: Description for the page
---



<p><code>tidymodels</code> is a collection of packages for modelling and machine learning in R, drawing on the tools and approach of the <code>tidyverse</code>. It is replacing <code>caret</code> as the main choice to work in supervised learning models.
The best way to start with <code>tidymodels</code> is with a small example. I have found <a href="https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/">this example of multiclass classification</a> with the <code>iris</code> dataset very helpful. Here I will present a similar workflow, but with a binary classification problem. Loading <code>tidymodels</code> only, we’ll have all the packages we need:</p>
<pre class="r"><code>library(tidymodels)</code></pre>
<p>Our job is to build a model predicting if an <code>iris</code> flower is of the species versicolor. This is a <strong>binary classification</strong> problem. It has some difficulty, as versicolor are close to virginica:</p>
<pre class="r"><code>ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) +
  geom_point(size=1.5) +
  theme_bw()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Let’s define the target variable. When using <code>tidymodels</code> in binary classification problems, the target variable:</p>
<ul>
<li>must be a <strong>factor</strong>,</li>
<li>with its <strong>first level</strong> corresponding to the <strong>positive</strong> class.</li>
</ul>
<pre class="r"><code>iris &lt;- iris |&gt; 
  mutate(is_versicolor = ifelse(Species == &quot;versicolor&quot;, &quot;versicolor&quot;, &quot;not_versicolor&quot;)) |&gt;
  mutate(is_versicolor = factor(is_versicolor, levels = c(&quot;versicolor&quot;, &quot;not_versicolor&quot;)))</code></pre>
<p>In binary classification problems, the class associated with the presence of a property is labelled <strong>positive</strong>. Here the positive class is that the flower <em>is</em> versicolor, that is <code>is_versicolor==versicolor</code>. The other class is labelled <strong>negative</strong>. Here that means that the flower <em>is not</em> versicolor <code>is_versicolor==not_versicolor</code>.</p>
<div id="data-preprocessing-with-recipes" class="section level2">
<h2>Data Preprocessing with recipes</h2>
<p>Data pre-processing in <code>tidymodels</code> is performed with the <code>recipes</code> package. A recipe has the following structure:</p>
<pre class="r"><code>iris_recipe &lt;- iris |&gt;
  recipe(is_versicolor ~.) |&gt;
  step_rm(Species) |&gt;
  step_corr(all_predictors()) |&gt;
  step_center(all_predictors(), -all_outcomes()) |&gt;
  step_scale(all_predictors(), -all_outcomes())</code></pre>
<p>The components of this recipe are:</p>
<ul>
<li>The <strong>data</strong> to apply the recipe, in this case the whole <code>iris</code>.</li>
<li>A <code>recipe</code> instruction defining the <strong>model</strong>: here we state that <code>is_versicolor</code> is the target variable, and the remaining variables the features.</li>
<li>Some <strong>steps</strong> to transform data. Here we remove <code>Species</code> with <code>step_rm</code>, look for correlated predictors with <code>step_corr</code>, center (substract the mean) and scale (divide by standard deviation) the predictors with <code>step_scale</code>.</li>
</ul>
<p>To see what the recipe has done we can just estimate doing:</p>
<pre class="r"><code>iris_recipe |&gt;
  prep()</code></pre>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          5
## 
## Training data contained 150 data points and no missing data.
## 
## Operations:
## 
## Variables removed Species [trained]
## Correlation filter on Petal.Length [trained]
## Centering for Sepal.Length, Sepal.Width, Petal.Width [trained]
## Scaling for Sepal.Length, Sepal.Width, Petal.Width [trained]</code></pre>
<p>We see that the recipe has removed <code>Petal.Length</code> because it was highly correlated with other variables. The next steps of the recipe have not been applied to that variable, so the order in which to apply the steps is relevant.</p>
</div>
<div id="defining-the-model-with-parsnip" class="section level2">
<h2>Defining the Model with parsnip</h2>
<p>The models in <code>tidymodels</code> are stored in <code>parsnip</code>, the successor of <code>caret</code> (whence its name). Here we define a random forest <strong>model</strong> with some parameters and specify the engine we are using. The <strong>engine</strong> in the <code>parsnip</code> context is the source of the code to run the model. It can be a package, a R base function, <code>stan</code> or <code>spark</code>, among others. Here we are using the random forest implemented in the <code>ranger</code> package.</p>
<pre class="r"><code>rf &lt;- rand_forest(mode = &quot;classification&quot;, trees = 100) |&gt;
  set_engine(&quot;ranger&quot;)</code></pre>
</div>
<div id="defining-a-workflow" class="section level2">
<h2>Defining a workflow</h2>
<p>Once we have a model and a recipe, we can put it all together with a <code>workflow</code>:</p>
<pre class="r"><code>iris_rf_wf &lt;- workflow() |&gt;
  add_recipe(iris_recipe) |&gt;
  add_model(rf)</code></pre>
<p>The workflow <code>iris_rf_wf</code> applies the preprocess recipe iris_recipe, and then builds the model <code>rf</code> with data applied to that recipe.</p>
</div>
<div id="obtaining-predictions" class="section level2">
<h2>Obtaining Predictions</h2>
<p>When we <code>fit</code>the workflow to <code>iris</code>, we obtain model hyperparameters using the <code>iris</code> dataset. Then, we can <code>predict</code> the class of each observation from the same data. As the outcome is set in a tibble format, we can use <code>bind_cols</code> to attach the prediction to the original data set.</p>
<pre class="r"><code>set.seed(3131)
iris_pred &lt;- iris_rf_wf |&gt;
  fit(iris) |&gt;
  predict(iris) |&gt;
  bind_cols(iris)</code></pre>
<p>Let’s examine the results:</p>
<pre class="r"><code>iris_pred |&gt; 
  glimpse()</code></pre>
<pre><code>## Rows: 150
## Columns: 7
## $ .pred_class   &lt;fct&gt; not_versicolor, not_versicolor, not_versicolor, not_vers…
## $ Sepal.Length  &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4…
## $ Sepal.Width   &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3…
## $ Petal.Length  &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1…
## $ Petal.Width   &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0…
## $ Species       &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, …
## $ is_versicolor &lt;fct&gt; not_versicolor, not_versicolor, not_versicolor, not_vers…</code></pre>
<p>We have the predicted outcome in the <code>.pred_class</code> variable. Note that the variable omitted in the recipe has not been removed from the dataset.</p>
</div>
<div id="evaluating-model-performance" class="section level2">
<h2>Evaluating model performance</h2>
<p>We can examine how well has performed the model with the <strong>confusion matrix</strong>:</p>
<pre class="r"><code>iris_pred |&gt;
  conf_mat(truth = is_versicolor, estimate = .pred_class)</code></pre>
<pre><code>##                 Truth
## Prediction       versicolor not_versicolor
##   versicolor             49              3
##   not_versicolor          1             97</code></pre>
<p>Let’s define a <code>metric_set</code> including the following parameters:</p>
<ul>
<li><strong>accuracy</strong>: the fraction of observations correctly classified,</li>
<li><strong>sensibility</strong>: the fraction of positive observations correctly classified,</li>
<li><strong>specificity</strong>: the fraction of negative observations correctly classified.</li>
</ul>
<p>The obtained values are:</p>
<pre class="r"><code>class_metrics &lt;- metric_set(accuracy, sens, spec)</code></pre>
<p>and estimate the values:</p>
<pre class="r"><code>iris_pred |&gt;
 class_metrics(truth = is_versicolor, estimate = .pred_class)</code></pre>
<pre><code>## # A tibble: 3 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.973
## 2 sens     binary         0.98 
## 3 spec     binary         0.97</code></pre>
<p>Here we see that</p>
<ul>
<li><strong>accuracy</strong> is (49+97)/(49+97+3+1) = 0.073,</li>
<li><strong>sensibility</strong> is equal to 49/(1+49) = 0.980,</li>
<li><strong>specificity</strong> is equal to 97/(97+3) = 0.970.</li>
</ul>
</div>
<div id="more-features-of-tidymodels" class="section level2">
<h2>More Features of tidymodels</h2>
<p>This is a very basic workflow of model training with <code>tidymodels</code>. There are many more features available, among others:</p>
<ul>
<li>train models of regression or numerical prediction,</li>
<li>define train and test sets, and test models with cross validation,</li>
<li>tune hyperparameter models,</li>
<li>use subsampling with unbalanced datasets,</li>
<li>use more performance metrics to build the model.</li>
</ul>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li><code>recipes</code> function reference: <a href="https://recipes.tidymodels.org/reference/index.html" class="uri">https://recipes.tidymodels.org/reference/index.html</a></li>
<li>list of available models in <code>parsnip</code>: <a href="https://www.tidymodels.org/find/parsnip/" class="uri">https://www.tidymodels.org/find/parsnip/</a></li>
</ul>
</div>
<div id="session-info" class="section level2">
<h2>Session Info</h2>
<pre><code>## R version 4.2.2 Patched (2022-11-10 r83330)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Linux Mint 21.1
## 
## Matrix products: default
## BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0
## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0
## 
## locale:
##  [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=es_ES.UTF-8    
##  [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=es_ES.UTF-8   
##  [7] LC_PAPER=es_ES.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] yardstick_1.1.0    workflowsets_1.0.0 workflows_1.1.2    tune_1.0.1        
##  [5] tidyr_1.3.0        tibble_3.1.8       rsample_1.1.1      recipes_1.0.4     
##  [9] purrr_1.0.1        parsnip_1.0.3      modeldata_1.1.0    infer_1.0.4       
## [13] ggplot2_3.4.0      dplyr_1.0.10       dials_1.1.0        scales_1.2.1      
## [17] broom_1.0.3        tidymodels_1.0.0  
## 
## loaded via a namespace (and not attached):
##  [1] sass_0.4.5          foreach_1.5.2       jsonlite_1.8.4     
##  [4] splines_4.2.2       prodlim_2019.11.13  bslib_0.4.2        
##  [7] assertthat_0.2.1    highr_0.10          GPfit_1.0-8        
## [10] yaml_2.3.7          globals_0.16.2      ipred_0.9-13       
## [13] pillar_1.8.1        backports_1.4.1     lattice_0.20-45    
## [16] glue_1.6.2          digest_0.6.31       hardhat_1.2.0      
## [19] colorspace_2.1-0    htmltools_0.5.4     Matrix_1.5-1       
## [22] timeDate_4022.108   pkgconfig_2.0.3     lhs_1.1.6          
## [25] DiceDesign_1.9      listenv_0.9.0       bookdown_0.32      
## [28] ranger_0.14.1       gower_1.0.1         lava_1.7.1         
## [31] timechange_0.2.0    farver_2.1.1        generics_0.1.3     
## [34] ellipsis_0.3.2      cachem_1.0.6        withr_2.5.0        
## [37] furrr_0.3.1         nnet_7.3-18         cli_3.6.0          
## [40] survival_3.5-3      magrittr_2.0.3      evaluate_0.20      
## [43] future_1.31.0       fansi_1.0.4         parallelly_1.34.0  
## [46] MASS_7.3-58.2       class_7.3-21        blogdown_1.16      
## [49] tools_4.2.2         lifecycle_1.0.3     munsell_0.5.0      
## [52] compiler_4.2.2      jquerylib_0.1.4     rlang_1.0.6        
## [55] grid_4.2.2          iterators_1.0.14    rstudioapi_0.14    
## [58] labeling_0.4.2      rmarkdown_2.20      gtable_0.3.1       
## [61] codetools_0.2-19    DBI_1.1.3           R6_2.5.1           
## [64] lubridate_1.9.1     knitr_1.42          fastmap_1.1.0      
## [67] future.apply_1.10.0 utf8_1.2.2          parallel_4.2.2     
## [70] Rcpp_1.0.10         vctrs_0.5.2         rpart_4.1.19       
## [73] tidyselect_1.2.0    xfun_0.36</code></pre>
<p>Updated at 2023-03-20 10:29:54</p>
</div>
